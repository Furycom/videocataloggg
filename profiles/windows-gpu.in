-r ../requirements.in
llama-cpp-python==0.2.90
onnxruntime-gpu==1.19.2
